{
 "metadata": {
  "name": "",
  "signature": "sha256:e3bd42ee230ec05992097723cb35d65b7615ba1bfd6936a6b667a91488bc7444"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section is about how to process especially categorical or nominal features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import nltk\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.github.com/nltk_data/\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk import word_tokenize\n",
      "from nltk.stem import PorterStemmer\n",
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "from nltk import pos_tag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordnet_tags = ['n', 'v']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [\n",
      "'He ate the sandwiches',\n",
      "'Every sandwich was eaten by him']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmer = PorterStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_tokenize(corpus[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['He', 'ate', 'the', 'sandwiches']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmer.stem(word_tokenize(corpus[0])[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "u'He'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Stemmed:', [[stemmer.stem(token) for token in word_tokenize(document)] for document in corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Stemmed: [[u'He', u'ate', u'the', u'sandwich'], [u'Everi', u'sandwich', u'wa', u'eaten', u'by', u'him']]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lemmatizer = WordNetLemmatizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_corpus = [pos_tag(word_tokenize(document)) for document in\n",
      "corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[[('He', 'PRP'), ('ate', 'VBP'), ('the', 'DT'), ('sandwiches', 'NNS')],\n",
        " [('Every', 'DT'),\n",
        "  ('sandwich', 'NN'),\n",
        "  ('was', 'VBD'),\n",
        "  ('eaten', 'VBN'),\n",
        "  ('by', 'IN'),\n",
        "  ('him', 'PRP')]]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lemmatizer.lemmatize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<bound method WordNetLemmatizer.lemmatize of <WordNetLemmatizer>>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_tag(word_tokenize(corpus[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[('He', 'PRP'), ('ate', 'VBP'), ('the', 'DT'), ('sandwiches', 'NNS')]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SMS Spam classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "read in the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_table('./SMSSpamCollection',delimiter = '\\t',header = None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.columns = ['class','text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>class</th>\n",
        "      <th>text</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  ham</td>\n",
        "      <td> Go until jurong point, crazy.. Available only ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  ham</td>\n",
        "      <td>                     Ok lar... Joking wif u oni...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> spam</td>\n",
        "      <td> Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  ham</td>\n",
        "      <td> U dun say so early hor... U c already then say...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  ham</td>\n",
        "      <td> Nah I don't think he goes to usf, he lives aro...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "  class                                               text\n",
        "0   ham  Go until jurong point, crazy.. Available only ...\n",
        "1   ham                      Ok lar... Joking wif u oni...\n",
        "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
        "3   ham  U dun say so early hor... U c already then say...\n",
        "4   ham  Nah I don't think he goes to usf, he lives aro..."
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['class'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "ham     4825\n",
        "spam     747\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Convert text to vectorized features using tfidfvectorizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtrain_raw,Xtest_raw,ytrain_raw,ytest_raw = train_test_split(df['text'],df['class'],random_state = 123)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Tf = TfidfVectorizer(stop_words='english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtrain = Tf.fit_transform(Xtrain_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest = Tf.transform(Xtest_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtrain.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(4179, 7205)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtest.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(1393, 7205)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Invoke Logistic Regression model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(Xtrain,ytrain_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytest_pred = clf.predict(Xtest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.classes_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array(['ham', 'spam'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Use complete report for evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classification_report(ytest_raw,ytest_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        ham       0.96      1.00      0.98      1201\n",
        "       spam       0.99      0.75      0.85       192\n",
        "\n",
        "avg / total       0.97      0.96      0.96      1393\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Now print out the confusion matrix, using the pd.crosstab"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print confusion_matrix(ytest_raw,ytest_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1200    1]\n",
        " [  48  144]]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pd.crosstab(ytest_raw,ytest_pred,rownames = ['true'],colnames = ['pred'],margins = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pred   ham  spam   All\n",
        "true                  \n",
        "ham   1200     1  1201\n",
        "spam    48   144   192\n",
        "All   1248   145  1393\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now this outcome is highly dependent on the specific train/test split, to mitigate this effect, use cross-validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note for cross_val_score calculation, more precisely the f1_score function requires the input of positive label,therefore the data has to be changed to binary. While this is not necessary for accuray calculation, it is necessary for recall, precision and f1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelBinarizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lb = LabelBinarizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytrain = lb.fit_transform(ytrain_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytrain = ytrain.flatten()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f1s = cross_val_score(clf,Xtrain,ytrain,cv = 5, scoring = 'f1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'F1 score',np.mean(f1s),f1s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1 score 0.707488631162 [ 0.77595628  0.71676301  0.64242424  0.68639053  0.71590909]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "ROC curve and AUC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ROC is for binary classification, or for multiclass one-vs-all"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve,auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytest_prob = clf.predict_proba(Xtest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Take note to the order of the probabilities, they are the same order as the self.class_"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.classes_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "array(['ham', 'spam'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convert manually the ytest to binary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytest_raw[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array(['ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham',\n",
        "       'spam'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytest = lb.fit_transform(ytest_raw).flatten()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytest[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1])"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr, recall,thresholds = roc_curve(ytest,ytest_prob[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "roc_auc = auc(fpr,recall)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresholds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "array([ 0.95192142,  0.94678119,  0.93771179, ...,  0.00865756,\n",
        "        0.0070737 ,  0.00581004])"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fpr[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot ROC figure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x1139a4a90>"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(fpr,recall,'b',label = 'AUC = {:.2f}'.format(roc_auc))\n",
      "plt.legend(loc='lower right')\n",
      "plt.plot([0, 1],[0, 1],'r--')\n",
      "plt.xlim([0, 1])\n",
      "plt.ylim([0, 1])\n",
      "plt.ylabel('Recall'),plt.xlabel('False Postive rate')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIikUGIQEZEUSgwiIpLi/wMcdxWVEWA/8wAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1139d7190>"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Tuning the model with grid search"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "tuning parameters are regularization value and thresholds used to remove words that appear too frequently or infrequently"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pip = Pipeline([\n",
      "    ('vect', TfidfVectorizer()),\n",
      "    ('clf', LogisticRegression()),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pip.steps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "          charset_error=None, decode_error=u'strict',\n",
        "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "          ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "          token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "          vocabulary=None)),\n",
        " ('clf',\n",
        "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "            intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TfidfVectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
        "        vocabulary=None)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {'vect__stop_words':('english',None),'vect__max_features':(2500,5000,10000,None),\n",
      "              'vect__ngram_range':((1,1),(1,2)),'vect__use_idf':(True,False),'vect__norm':('l1','l2'),'vect__max_df':(0.25,0.5,0.75),\n",
      "              'clf__penalty':('l1','l2'),'clf__C':(0.01,0.1,1,10)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search = GridSearchCV(pip,param_grid = parameters,scoring = 'accuracy',cv = 3,n_jobs = -1,verbose = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_search.fit(Xtrain_raw,ytrain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 1536 candidates, totalling 4608 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    1.8s\n",
        "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:    7.3s\n",
        "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:   16.6s\n",
        "[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:   30.0s\n",
        "[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed:   47.7s\n",
        "[Parallel(n_jobs=-1)]: Done 1800 jobs       | elapsed:  1.2min\n",
        "[Parallel(n_jobs=-1)]: Done 2450 jobs       | elapsed:  1.6min\n",
        "[Parallel(n_jobs=-1)]: Done 3200 jobs       | elapsed:  2.1min\n",
        "[Parallel(n_jobs=-1)]: Done 4050 jobs       | elapsed:  3.6min\n",
        "[Parallel(n_jobs=-1)]: Done 4594 out of 4608 | elapsed:  4.0min remaining:    0.7s\n",
        "[Parallel(n_jobs=-1)]: Done 4608 out of 4608 | elapsed:  4.0min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "GridSearchCV(cv=3,\n",
        "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm...e, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'vect__ngram_range': ((1, 1), (1, 2)), 'vect__stop_words': ('english', None), 'vect__max_df': (0.25, 0.5, 0.75), 'vect__norm': ('l1', 'l2'), 'vect__use_idf': (True, False), 'clf__C': (0.01, 0.1, 1, 10), 'clf__penalty': ('l1', 'l2'), 'vect__max_features': (2500, 5000, 10000, None)},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring='accuracy', verbose=1)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Best score: {:.3f}'.format(grid_search.best_score_)\n",
      "print 'Best parameters set:'\n",
      "best_parameters = grid_search.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print '{}: {}'.format(param_name,best_parameters[param_name])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score: 0.986\n",
        "Best parameters set:\n",
        "clf__C: 10\n",
        "clf__penalty: l2\n",
        "vect__max_df: 0.5\n",
        "vect__max_features: 10000\n",
        "vect__ngram_range: (1, 2)\n",
        "vect__norm: l2\n",
        "vect__stop_words: None\n",
        "vect__use_idf: True\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ytest_pred2 = grid_search.predict(Xtest_raw)\n",
      "print classification_report(ytest,ytest_pred2,labels = [0, 1],target_names=['ham','spam'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        ham       0.98      1.00      0.99      1201\n",
        "       spam       0.99      0.90      0.94       192\n",
        "\n",
        "avg / total       0.98      0.98      0.98      1393\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Multi-class classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use Kaggle movie sentiment data: http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('./moviereviews/train.tsv',delimiter='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PhraseId</th>\n",
        "      <th>SentenceId</th>\n",
        "      <th>Phrase</th>\n",
        "      <th>Sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> A series of escapades demonstrating the adage ...</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> A series of escapades demonstrating the adage ...</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td>                                          A series</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td>                                                 A</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td>                                            series</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "   PhraseId  SentenceId                                             Phrase  \\\n",
        "0         1           1  A series of escapades demonstrating the adage ...   \n",
        "1         2           1  A series of escapades demonstrating the adage ...   \n",
        "2         3           1                                           A series   \n",
        "3         4           1                                                  A   \n",
        "4         5           1                                             series   \n",
        "\n",
        "   Sentiment  \n",
        "0          1  \n",
        "1          2  \n",
        "2          2  \n",
        "3          2  \n",
        "4          2  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PhraseId      156060\n",
        "SentenceId    156060\n",
        "Phrase        156060\n",
        "Sentiment     156060\n",
        "dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 156060 entries, 0 to 156059\n",
        "Data columns (total 4 columns):\n",
        "PhraseId      156060 non-null int64\n",
        "SentenceId    156060 non-null int64\n",
        "Phrase        156060 non-null object\n",
        "Sentiment     156060 non-null int64\n",
        "dtypes: int64(3), object(1)\n",
        "memory usage: 6.0+ MB\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['Sentiment'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "2    79582\n",
        "3    32927\n",
        "1    27273\n",
        "4     9206\n",
        "0     7072\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pip2 = Pipeline([('vect',TfidfVectorizer()),('clf',LogisticRegression())])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {'vect__max_df':[0.25, 0.5],'vect__ngram_range':[(1,1),(1,2)],'vect__use_idf':[True,False],'clf__C': [0.1,1,10]}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = df['Phrase'],df['Sentiment']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size = 0.5,random_state = 123)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs2 = GridSearchCV(pip2,parameters,n_jobs=3,verbose = 1,scoring = 'accuracy')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs2.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=3)]: Done   1 jobs       | elapsed:    1.5s\n",
        "[Parallel(n_jobs=3)]: Done  50 jobs       | elapsed:   46.7s\n",
        "[Parallel(n_jobs=3)]: Done  68 out of  72 | elapsed:  1.3min remaining:    4.5s\n",
        "[Parallel(n_jobs=3)]: Done  72 out of  72 | elapsed:  1.4min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm...e, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=3,\n",
        "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__use_idf': [True, False], 'clf__C': [0.1, 1, 10], 'vect__max_df': [0.25, 0.5]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring='accuracy', verbose=1)"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Best score is {:.3f}'.format(gs2.best_score_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score is 0.631\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Best parameters set:'\n",
      "best_parameters = gs2.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print '{}: {}'.format(param_name,best_parameters[param_name])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best parameters set:\n",
        "clf__C: 10\n",
        "vect__max_df: 0.5\n",
        "vect__ngram_range: (1, 2)\n",
        "vect__use_idf: False\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs2.best_estimator_.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "{'clf': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
        "           intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001),\n",
        " 'clf__C': 10,\n",
        " 'clf__class_weight': None,\n",
        " 'clf__dual': False,\n",
        " 'clf__fit_intercept': True,\n",
        " 'clf__intercept_scaling': 1,\n",
        " 'clf__penalty': 'l2',\n",
        " 'clf__random_state': None,\n",
        " 'clf__tol': 0.0001,\n",
        " 'vect': TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "         charset_error=None, decode_error=u'strict',\n",
        "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "         lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
        "         ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
        "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
        "         token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
        "         vocabulary=None),\n",
        " 'vect__analyzer': u'word',\n",
        " 'vect__binary': False,\n",
        " 'vect__charset': None,\n",
        " 'vect__charset_error': None,\n",
        " 'vect__decode_error': u'strict',\n",
        " 'vect__dtype': numpy.int64,\n",
        " 'vect__encoding': u'utf-8',\n",
        " 'vect__input': u'content',\n",
        " 'vect__lowercase': True,\n",
        " 'vect__max_df': 0.5,\n",
        " 'vect__max_features': None,\n",
        " 'vect__min_df': 1,\n",
        " 'vect__ngram_range': (1, 2),\n",
        " 'vect__norm': u'l2',\n",
        " 'vect__preprocessor': None,\n",
        " 'vect__smooth_idf': True,\n",
        " 'vect__stop_words': None,\n",
        " 'vect__strip_accents': None,\n",
        " 'vect__sublinear_tf': False,\n",
        " 'vect__token_pattern': u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        " 'vect__tokenizer': None,\n",
        " 'vect__use_idf': False,\n",
        " 'vect__vocabulary': None}"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A complete classification report"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = gs2.predict(X_test)\n",
      "print classification_report(y_test,predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.51      0.33      0.40      3462\n",
        "          1       0.54      0.45      0.49     13629\n",
        "          2       0.71      0.83      0.76     39847\n",
        "          3       0.58      0.50      0.54     16470\n",
        "          4       0.55      0.37      0.44      4622\n",
        "\n",
        "avg / total       0.63      0.65      0.63     78030\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another aspect is the confusion matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(predictions, y_test,rownames = ['predicted'],colnames = ['true'],margins = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th>true</th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>All</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>predicted</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1136</td>\n",
        "      <td>   891</td>\n",
        "      <td>   188</td>\n",
        "      <td>     6</td>\n",
        "      <td>    2</td>\n",
        "      <td>  2223</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1675</td>\n",
        "      <td>  6131</td>\n",
        "      <td>  3130</td>\n",
        "      <td>   386</td>\n",
        "      <td>   35</td>\n",
        "      <td> 11357</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  597</td>\n",
        "      <td>  6178</td>\n",
        "      <td> 33159</td>\n",
        "      <td>  6595</td>\n",
        "      <td>  470</td>\n",
        "      <td> 46999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>   48</td>\n",
        "      <td>   400</td>\n",
        "      <td>  3230</td>\n",
        "      <td>  8280</td>\n",
        "      <td> 2400</td>\n",
        "      <td> 14358</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>    6</td>\n",
        "      <td>    29</td>\n",
        "      <td>   140</td>\n",
        "      <td>  1203</td>\n",
        "      <td> 1715</td>\n",
        "      <td>  3093</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>All</th>\n",
        "      <td> 3462</td>\n",
        "      <td> 13629</td>\n",
        "      <td> 39847</td>\n",
        "      <td> 16470</td>\n",
        "      <td> 4622</td>\n",
        "      <td> 78030</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "true          0      1      2      3     4    All\n",
        "predicted                                        \n",
        "0          1136    891    188      6     2   2223\n",
        "1          1675   6131   3130    386    35  11357\n",
        "2           597   6178  33159   6595   470  46999\n",
        "3            48    400   3230   8280  2400  14358\n",
        "4             6     29    140   1203  1715   3093\n",
        "All        3462  13629  39847  16470  4622  78030"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Summary: prediction did bad with the extreme reviews, often mistaken them for mild or more neutral reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "(78030,)"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(y_test).value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "2    39847\n",
        "3    16470\n",
        "1    13629\n",
        "4     4622\n",
        "0     3462\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now change the scoring functions, 1. emphasize solely on recall"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because I want to adjust the parameters for recall, I need to generate a score function using makescorer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import recall_score,make_scorer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recall_scorer = make_scorer(recall_score,average = 'macro')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs3 = GridSearchCV(pip2,parameters,n_jobs=-1,verbose = 1,scoring = recall_scorer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs3.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    2.2s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   31.4s\n",
        "[Parallel(n_jobs=-1)]: Done  58 out of  72 | elapsed:   47.1s remaining:   11.4s\n",
        "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   59.9s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm...e, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__use_idf': [True, False], 'clf__C': [0.1, 1, 10], 'vect__max_df': [0.25, 0.5]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring=make_scorer(recall_score, average=macro), verbose=1)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def best_est_report(gsobj,parameters):\n",
      "    # input: gs object\n",
      "    #        parameters as an dictionary\n",
      "    # print out the best score\n",
      "    # and the best parameters set\n",
      "    print 'the best score is {:.2f}'.format(gsobj.best_score_)\n",
      "    best_parameters = gsobj.best_estimator_.get_params()\n",
      "    for parameter in sorted(parameters.keys()):\n",
      "        print '{}: {}'.format(parameter,best_parameters[parameter])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_est_report(gs3,parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the best score is 0.48\n",
        "clf__C: 10\n",
        "vect__max_df: 0.25\n",
        "vect__ngram_range: (1, 2)\n",
        "vect__use_idf: True\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred3 = gs3.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classification_report(y_test,pred3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.49      0.34      0.40      3462\n",
        "          1       0.53      0.46      0.49     13629\n",
        "          2       0.70      0.82      0.76     39847\n",
        "          3       0.57      0.50      0.53     16470\n",
        "          4       0.54      0.38      0.44      4622\n",
        "\n",
        "avg / total       0.63      0.64      0.63     78030\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now change the average to weighted which is the default choice for recall, therefore 'recall' can be given to scoring"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs4 = GridSearchCV(pip2,parameters,n_jobs=-1,verbose = 1,scoring = 'recall')\n",
      "gs4.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    2.5s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   30.9s\n",
        "[Parallel(n_jobs=-1)]: Done  58 out of  72 | elapsed:   46.9s remaining:   11.3s\n",
        "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   59.2s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm...e, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__use_idf': [True, False], 'clf__C': [0.1, 1, 10], 'vect__max_df': [0.25, 0.5]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring='recall', verbose=1)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred4 = gs4.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classification_report(y_test,pred4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.51      0.33      0.40      3462\n",
        "          1       0.54      0.45      0.49     13629\n",
        "          2       0.71      0.83      0.76     39847\n",
        "          3       0.58      0.50      0.54     16470\n",
        "          4       0.55      0.37      0.44      4622\n",
        "\n",
        "avg / total       0.63      0.65      0.63     78030\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusion is that the model is not very sensitive to the scoring function without any change to other parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import fbeta_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fbeta_scorer = make_scorer(fbeta_score,beta = float('Inf'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs5 = GridSearchCV(pip2, parameters, n_jobs = -1, verbose = 1, scoring = fbeta_scorer)\n",
      "gs5.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    2.4s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   32.3s\n",
        "[Parallel(n_jobs=-1)]: Done  58 out of  72 | elapsed:   51.2s remaining:   12.3s\n",
        "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  1.1min finished\n",
        "/Users/ysfeng/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/Users/ysfeng/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/Users/ysfeng/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/Users/ysfeng/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/Users/ysfeng/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm...e, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__use_idf': [True, False], 'clf__C': [0.1, 1, 10], 'vect__max_df': [0.25, 0.5]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring=make_scorer(fbeta_score, beta=inf), verbose=1)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_est_report(gs4,parameters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the best score is 0.63\n",
        "clf__C: 10\n",
        "vect__max_df: 0.5\n",
        "vect__ngram_range: (1, 2)\n",
        "vect__use_idf: False\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Test SGD classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pip3 = Pipeline([('vect',TfidfVectorizer()),('clf',SGDClassifier(shuffle = True,random_state = 123))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters2 = {'vect__max_df':[0.25, 0.5],'vect__ngram_range':[(1,1),(1,2)],'vect__use_idf':[True,False],'clf__alpha':np.logspace(\n",
      "-6,-1,6),'clf__loss':['hinge','log'],'clf__class_weight':[None,'auto']\n",
      "               }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs5 = GridSearchCV(pip3,parameters2,n_jobs = -1, verbose = 1,scoring = 'accuracy')\n",
      "gs5.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.6s\n",
        "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   18.6s\n",
        "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:  1.4min\n",
        "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:  3.0min\n",
        "[Parallel(n_jobs=-1)]: Done 562 out of 576 | elapsed:  3.7min remaining:    5.5s\n",
        "[Parallel(n_jobs=-1)]: Done 576 out of 576 | elapsed:  3.8min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 1), norm...=1, penalty='l2', power_t=0.5,\n",
        "       random_state=123, shuffle=True, verbose=0, warm_start=False))]),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__max_df': [0.25, 0.5], 'clf__loss': ['hinge', 'log'], 'vect__use_idf': [True, False], 'clf__class_weight': [None, 'auto'], 'clf__alpha': array([  1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,\n",
        "         1.00000e-02,   1.00000e-01])},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
        "       scoring='accuracy', verbose=1)"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_est_report(gs5,parameters2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the best score is 0.62\n",
        "clf__alpha: 1e-05\n",
        "clf__class_weight: None\n",
        "clf__loss: hinge\n",
        "vect__max_df: 0.25\n",
        "vect__ngram_range: (1, 2)\n",
        "vect__use_idf: False\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Multi-label classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}